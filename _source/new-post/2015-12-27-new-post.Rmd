---
layout: post
title:  Scraping HTML Tables
date: `r Sys.time()`
published: true
tags: [r, webscraping, rvest, xml]
---

In my [previous blog post](http://bradleyboehmke.github.io/scraping_tabular_data/) I started a series that covers common web scraping capabilities offered by R. In that first post I covered how to import tabular (i.e. .txt, .csv) or Excel files that are being hosted online.  In this post I cover how to scrape data from another common structure of data storage on the Web - HTML tables. The simplest approach to scraping HTML table data directly into R is by using either the XML package or the `rvest` package.  I will illustrate with this [BLS employment statistics webpage](http://www.bls.gov/web/empsit/cesbmart.htm) which contains multiple HTML tables.  

## Scraping HTML tables with XML 
The XML package provides a convenient `readHTMLTable()` function to extract data from HTML tables in HTML documents.  By passing the URL to `readHTMLTable()`, the data in each table is read and stored as a data frame.  In a case like this where multiple tables exists, the data frames will be stored in a list as illustrated.

```{r, collapse=TRUE, warning=FALSE, message=FALSE, cache=TRUE}
library(XML)

url <- "http://www.bls.gov/web/empsit/cesbmart.htm"

# read in HTML data
tbls <- readHTMLTable(url)

typeof(tbls)

length(tbls)
```

The list `tbl` contains 15 items.  This includes data from the 10 data tables seen on the webpage but also includes data from a few additional tables used to format parts of the page (i.e. table of contents, table of figures, advertisements). Using `str(tbl)`, you can investigate the data frames in the list to help identify the data you are interested in pulling.  Lets assume we are interested in pulling data from the second and third tables on the webpage (i) *Table 2. Nonfarm employment benchmarks by industry, March 2014 (in thousands)* and (ii) *Table 3. Net birth/death estimates by industry supersector, April â€“ December 2014 (in thousands)*.  By assessing `str(tbl)` you will see that these data are captured as the third and fourth items in `tbl` with the convenient titles `Table2` and `Table3` respectively. 

You can access these two data frames via normal list [subsetting](http://bradleyboehmke.github.io/tutorials/list#subsetting) or by using the `which` argument in `readHTMLTable()` which restricts the data importing to only those tables specified.  Also, note that the variables in Table 2 have variable names: `V1`, `V2`,...,`V8`.  When HTML tables have split headers as is the case with Table 2, the variable names are stripped and replaced with generic names because R does not know which variable names should align with each column.

```{r, collapse=TRUE, warning=FALSE, message=FALSE, cache=TRUE}
head(tbls[[3]])

head(tbls[[4]], 3)

# an alternative is to explicitly state which 
# table(s) to download
emp_ls <- readHTMLTable(url, which = c(3,4))

str(emp_ls)
```

## Scraping HTML tables with rvest

```{r, echo=FALSE, message=FALSE}
library(rvest)
```

[`rvest`](https://cran.r-project.org/web/packages/rvest/index.html) is a relatively newer package created by the RStudio team inspired by libraries such as [beautiful soup](http://www.crummy.com/software/BeautifulSoup/). `rvest` provides multiple functionalities such as extracting tag names, text, data, and attributes; detecting and repairing encoding issues; navigating around a website and more.  However, this post focuses only on extracting HTML table data with `rvest`.

To extract the table(s) of interest we first use the `html_nodes()` function to select the CSS nodes of interest.  In this case we are interested in all table nodes that exist in the webpage. `html_nodes` will capture all 15 HTML tables similar to `XML`'s `readHTMLTable()`. However, `html_nodes` does not parse the data; rather, it acts as a CSS selector.

```{r, collapse=TRUE, warning=FALSE, message=FALSE, cache=TRUE}
library(rvest)

webpage <- read_html("http://www.bls.gov/web/empsit/cesbmart.htm")

tbls <- html_nodes(webpage, "table")

head(tbls)
```

Looking through `tbls` we can see that the two tables of interest ("Table2" & "Table3") are captured as list items 3 & 4 above. We can now use `html_table()` to parse the HTML tables into data frames.  Since we are extracting two tables `html_table()` will create a list containing two data frames for the HTML tables parsed. Also, note that `rvest` makes use of the pipe operator (`%>%`) developed through the [`magrittr` package](https://cran.r-project.org/web/packages/magrittr/index.html).  You can read more about the functionality and benefits of `%>%` [here](http://www.r-bloggers.com/simpler-r-coding-with-pipes-the-present-and-future-of-the-magrittr-package/) and [here](http://blog.revolutionanalytics.com/2014/07/magrittr-simplifying-r-code-with-pipes.html).

```{r, collapse=TRUE}
webpage <- read_html("http://www.bls.gov/web/empsit/cesbmart.htm")

tbls_ls <- webpage %>%
        html_nodes("table") %>%
        .[3:4] %>%
        html_table(fill = TRUE)

str(tbls_ls)
```

One difference to note when using `rvest`'s `html_table` versus using `XML`'s `readHTMLTable` is when reading split column headings.  As we saw earlier in this chapter, `readHTMLTable` will cause split headings to be stripped and replaced with generic "VX" titles.  `html_table` , on other hand, will cause split headings to be included and can cause the first row to include parts of the headings.  We can see this with Table 2.  This may require some data clean up.

```{r, collapse=TRUE, warning=FALSE, message=FALSE}

head(tbls_ls[[1]], 4)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-1,]

# rename table headings
colnames(tbls_ls[[1]]) <- c("CES_Code", "Ind_Title", "Benchmark",
                            "Estimate", "Amt_Diff", "Pct_Diff")

head(tbls_ls[[1]], 4)

```

Although short, this post helps to illustrate how simple it can be to scrape data from HTML tables.  In the next post, we'll look at approaches to scrape text for purposes of textual and sentiment analysis.
